


# Spring

## Spring IOC & AOP

### IOC

IoC（Inverse of Control:控制反转）是一种**设计思想**，就是 **将原本在程序中手动创建对象的控制权，交由Spring框架来管理。** IoC 在其他语言中也有应用，并非 Spring 特有。 **IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。**

将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。 **IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。** 在实际项目中一个 Service 类可能有几百甚至上千个类作为它的底层，假如我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IoC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。

Spring 时代我们一般通过 XML 文件来配置 Bean，后来开发人员觉得 XML 文件来配置不太好，于是 SpringBoot 注解配置就慢慢开始流行起来。

推荐阅读：https://www.zhihu.com/question/23277575/answer/169698662

**Spring IoC的初始化过程：**

![Spring IoC的初始化过程](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/SpringIOC%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B.png)

IoC源码阅读

- https://javadoop.com/post/spring-ioc

### AOP

AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，**却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来**，便于**减少系统的重复代码**，**降低模块间的耦合度**，并**有利于未来的可拓展性和可维护性**。

**Spring AOP就是基于动态代理的**，如果要代理的对象，实现了某个接口，那么Spring AOP会使用**JDK Proxy**，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候Spring AOP会使用**Cglib** ，这时候Spring AOP会使用 **Cglib** 生成一个被代理对象的子类来作为代理，如下图所示：

![SpringAOPProcess](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/SpringAOPProcess.jpg)

当然你也可以使用 AspectJ ,Spring AOP 已经集成了AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。

使用 AOP 之后我们可以把一些通用功能抽象出来，在需要用到的地方直接使用即可，这样大大简化了代码量。我们需要增加新功能时也方便，这样也提高了系统扩展性。日志功能、事务管理等等场景都用到了 AOP 。

### Spring MVC

#### 说说自己对于 Spring MVC 了解

谈到这个问题，我们不得不提提之前 Model1 和 Model2 这两个没有 Spring MVC 的时代。

- **Model1 时代** : 很多学 Java 后端比较晚的朋友可能并没有接触过 Model1 模式下的 JavaWeb 应用开发。在 Model1 模式下，整个 Web 应用几乎全部用 JSP 页面组成，只用少量的 JavaBean 来处理数据库连接、访问等操作。这个模式下 JSP 既是控制层又是表现层。显而易见，这种模式存在很多问题。比如①将控制逻辑和表现逻辑混杂在一起，导致代码重用率极低；②前端和后端相互依赖，难以进行测试并且开发效率极低；
- **Model2 时代** ：学过 Servlet 并做过相关 Demo 的朋友应该了解“Java Bean(Model)+ JSP（View,）+Servlet（Controller） ”这种开发模式,这就是早期的 JavaWeb MVC 开发模式。Model:系统涉及的数据，也就是 dao 和 bean。View：展示模型中的数据，只是用来展示。Controller：处理用户请求都发送给 ，返回数据给 JSP 并展示给用户。

Model2 模式下还存在很多问题，Model2的抽象和封装程度还远远不够，使用Model2进行开发时不可避免地会重复造轮子，这就大大降低了程序的可维护性和复用性。于是很多JavaWeb开发相关的 MVC 框架应运而生比如Struts2，但是 Struts2 比较笨重。随着 Spring 轻量级开发框架的流行，Spring 生态圈出现了 Spring MVC 框架， Spring MVC 是当前最优秀的 MVC 框架。相比于 Struts2 ， Spring MVC 使用更加简单和方便，开发效率更高，并且 Spring MVC 运行速度更快。

MVC 是一种设计模式,Spring MVC 是一款很优秀的 MVC 框架。Spring MVC 可以帮助我们进行更简洁的Web层的开发，并且它天生与 Spring 框架集成。Spring MVC 下我们一般把后端项目分为 Service层（处理业务）、Dao层（数据库操作）、Entity层（实体类）、Controller层(控制层，返回数据给前台页面)。

**Spring MVC 的简单原理图如下：**

![img](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-10-11/60679444.jpg)

#### SpringMVC 工作原理了解吗?

**原理如下图所示：** ![SpringMVC运行原理](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-10-11/49790288.jpg)

上图的一个笔误的小问题：Spring MVC 的入口函数也就是前端控制器 `DispatcherServlet` 的作用是接收请求，响应结果。

**流程说明（重要）：**

1. 客户端（浏览器）发送请求，直接请求到 `DispatcherServlet`。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。
3. 解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由 `HandlerAdapter` 适配器处理。
4. `HandlerAdapter` 会根据 `Handler `来调用真正的处理器来处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回一个 `ModelAndView` 对象，`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
6. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
7. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
8. 把 `View` 返回给请求者（浏览器）


# Java

## 对于反射的理解，有什么好处？ 

JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 java 语言的反射机制。

### 反射机制优缺点

- **优点：** 运行期类型的判断，动态加载类，提高代码灵活度。
- **缺点：** 1,性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的 java 代码要慢很多。2,安全问题，让我们可以动态操作改变类的属性同时也增加了类的安全隐患。

### 反射的应用场景

- 在我们平时的项目开发过程中，基本上很少会直接使用到反射机制，但这不能说明反射机制没有用。
- 我们在使用 JDBC 连接数据库时使用 `Class.forName()`通过反射加载数据库的驱动程序；
- Spring 框架的 IOC（动态加载管理 Bean）创建对象以及 AOP（动态代理）功能都和反射有联系；
- 动态配置实例的属性；
- 通过反射使得项目复用性变高，且整体项目更易维护。

## 类如何加载？双亲委派？你怎么能实现类加载机制？有什么需要考虑的吗？ 

### 类加载过程

类加载过程：**加载->连接->初始化**。连接过程又可分为三步:**验证->准备->解析**。

![类加载过程](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B.png)

一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 `loadClass()` 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。

所有的类都由类加载器加载，加载的作用就是将 .class文件加载到内存。



### 类加载器种类

JVM 中内置了三个重要的 ClassLoader，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自`java.lang.ClassLoader`：

1. **BootstrapClassLoader(启动类加载器)** ：最顶层的加载类，由C++实现，负责加载 `%JAVA_HOME%/lib`目录下的jar包和类或者或被 `-Xbootclasspath`参数指定的路径中的所有类。
2. **ExtensionClassLoader(扩展类加载器)** ：主要负责加载目录 `%JRE_HOME%/lib/ext` 目录下的jar包和类，或被 `java.ext.dirs` 系统变量所指定的路径下的jar包。
3. **AppClassLoader(应用程序类加载器)** :面向我们用户的加载器，负责加载当前应用classpath下的所有jar包和类。

### 双亲委派模型

#### 双亲委派模型介绍

每一个类都有一个对应它的类加载器。系统中的 ClassLoder 在协同工作的时候会默认使用 **双亲委派模型** 。即在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，首先会把该请求委派该父类加载器的 `loadClass()` 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 `BootstrapClassLoader` 中。当父类加载器无法处理时，才由自己来处理。当父类加载器为null时，会使用启动类加载器 `BootstrapClassLoader` 作为父类加载器。



![ClassLoader](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/classloader_WPS%E5%9B%BE%E7%89%87.png)

#### 双亲委派模型实现源码分析

双亲委派模型的实现代码非常简单，逻辑非常清晰，都集中在 `java.lang.ClassLoader` 的 `loadClass()` 中，相关代码如下所示。



```java
private final ClassLoader parent; 
protected Class<?> loadClass(String name, boolean resolve)
        throws ClassNotFoundException
    {
        synchronized (getClassLoadingLock(name)) {
            // 首先，检查请求的类是否已经被加载过
            Class<?> c = findLoadedClass(name);
            if (c == null) {
                long t0 = System.nanoTime();
                try {
                    if (parent != null) {//父加载器不为空，调用父加载器loadClass()方法处理
                        c = parent.loadClass(name, false);
                    } else {//父加载器为空，使用启动类加载器 BootstrapClassLoader 加载
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                   //抛出异常说明父类加载器无法完成加载请求
                }
                
                if (c == null) {
                    long t1 = System.nanoTime();
                    //自己尝试加载
                    c = findClass(name);

                    // this is the defining class loader; record the stats
                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                    sun.misc.PerfCounter.getFindClasses().increment();
                }
            }
            if (resolve) {
                resolveClass(c);
            }
            return c;
        }
    }
```

#### 使用双亲委派模型的好处

双亲委派模型保证了Java程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 API 不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 `java.lang.Object` 类的话，那么程序运行的时候，系统就会出现多个不同的 `Object` 类。



## 说说你使用的集合？底层了解多少？

链接1：https://snailclimb.gitee.io/javaguide/#/docs/java/collection/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98

### ArrayList怎么扩容？

ArrayList 不想像数组这样活着，它想能屈能伸，所以它实现了动态扩容。一旦在添加元素的时候，发现容量用满了 `s == elementData.length`，就按照原来数组的 1.5 倍（`oldCapacity >> 1`）进行扩容。扩容之后，再将原有的数组复制到新分配的内存地址上 `Arrays.copyOf(elementData, newCapacity)`。

### ArrayList是线程安全的吗？

ArrayList线程不安全，其add方法和remove方法都是不安全的。

**对于add方法：**

``` java
public boolean add(E e) {

    /**
     * 添加一个元素时，做了如下两步操作
     * 1.判断列表的capacity容量是否足够，是否需要扩容
     * 2.真正将元素放在列表的元素数组里面
     */
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    elementData[size++] = e;
    return true;
}
```
ensureCapacityInternal()这个方法的详细代码我们可以暂时不看，它的作用就是判断如果将当前的新元素加到列表后面，列表的elementData数组的大小是否满足，如果size + 1的这个需求长度大于了elementData这个数组的长度，那么就要对这个数组进行扩容。

由此看到add元素时，实际做了两个大的步骤：

- 判断elementData数组容量是否满足需求
- 在elementData对应位置上设置值

这样也就出现了第一个导致线程不安全的隐患，在多个线程进行add操作时可能会导致elementData数组越界。具体逻辑如下：

列表大小为9，即size=9
线程A开始进入add方法，这时它获取到size的值为9，调用ensureCapacityInternal方法进行容量判断。
线程B此时也进入add方法，它获取到size的值也为9，也开始调用ensureCapacityInternal方法。
线程A发现需求大小为10，而elementData的大小就为10，可以容纳。于是它不再扩容，返回。
线程B也发现需求大小为10，也可以容纳，返回。
线程A开始进行设置值操作， elementData[size++] = e 操作。此时size变为10。
线程B也开始进行设置值操作，它尝试设置elementData[10] = e，而elementData没有进行过扩容，它的下标最大为9。于是此时会报出一个数组越界的异常ArrayIndexOutOfBoundsException.



**对于remove方法：**

remove操作分为三部分：边界检查；检查是否需要移动元素；清除该位置元素。

假设有两个list的size位5，1.线程A执行remove(4)，2.线程B执行remove(4)，3.线程A进行边界检查，发现没问题，4.线程B进行边界检查，发现没问题，5. 线程A清除元素，成功删除，6. 线程B执行清除元素，报错，因为此时index=4已经越界了。



#### 使用synchronized关键字

使用synchronized关键字可以保证线程安全，但是由此带来的是效率低下。

#### Collections.synchronizedList()
使用Collections.synchronizedList()，得到一个线程安全的List

#### CopyOnWriteArrayList

CopyOnWriteArrayList使用了一种叫写时复制的方法，当有新元素添加到CopyOnWriteArrayList时，先从原有的数组中拷贝一份出来，然后在新的数组做写操作，写完之后，再将原来的数组引用指向到新数组。



**- 写操作**

当有新元素加入的时候，如下图，创建新数组，并往新数组中加入一个新元素,这个时候，array这个引用仍然是指向原数组的。
![这里写图片描述](https://img-blog.csdn.net/20170117145928110?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGluc29uZ2JpbjE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](https://img-blog.csdn.net/20170117150336836?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGluc29uZ2JpbjE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

`CopyOnWriteArrayList`的整个add操作都是在**锁**的保护下进行的。
这样做是为了避免在多线程并发add的时候，**复制出多个副本出来**,把数据搞乱了，导致最终的数组数据不是我们期望的。

**- 读操作**

由于所有的写操作都是在新数组进行的，这个时候如果有线程并发的写，则通过锁来控制，如果有线程并发的读，则分几种情况：
1、如果写操作未完成，那么直接读取原数组的数据；
2、如果写操作完成，但是引用还未指向新数组，那么也是读取原数组数据；
3、如果写操作完成，并且引用已经指向了新的数组，那么直接从新数组中读取数据。

可见，CopyOnWriteArrayList的读操作是可以不用加锁的。





## JAVA中重写equals()方法为什么要重写hashcode()方法?

当我们重写equals方法后，认为只要两个对象的成员变量值相同，就返回true。但是如果没有重写hashcode()的话，两者返回的hashcode值是不一样的，所以就认为是不同对象，所以就重复插入了。

## Java中的final关键字？

1. 修改类。当用final修饰一个类时，表明这个类不能被继承。final类中的成员变量可以根据需要设为final，但是要注意final类中的所有成员方法都会被隐式地指定为final方法。

2. 修饰方法。当用final修饰一个方法时，表明该方法不能被子类重写。还有另外一个原因，早期设置final方法是想通过转为内嵌调用，从而提升性能。

3. 修改变量
	- 基本类型。如果是基本类型，则表明这个变量的值不能再改变了。
	- 引用类型。如果是引用类型，则表明这个变量不能再指向其他对象，但是原来的对象还是可以发生改变。

## Java中的static关键字？

static方法就是没有this的方法。在static方法内部不能调用非静态方法，反过来是可以的。而且可以在没有创建任何对象的前提下，仅仅通过类本身来调用static方法。这实际上正是static方法的主要用途。

一句话描述：方便在没有创建对象的情况下来进行调用（方法/变量）。

### static方法

它不依附于任何对象，既然都没有对象，就谈不上this了。并且由于这个特性，在静态方法中不能访问类的非静态成员变量和非静态成员方法，因为非静态成员方法/变量都是必须依赖具体的对象才能够被调用。

但是要注意的是，虽然在静态方法中不能访问非静态成员方法和非静态成员变量，但是在非静态成员方法中是可以访问静态成员方法/变量的。

### static变量

static变量也称作静态变量，静态变量和非静态变量的区别是：静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响。

### static代码块

static关键字还有一个比较关键的作用就是 用来形成静态代码块以优化程序性能。static块可以置于类中的任何地方，类中可以有多个static块。在类初次被加载的时候，会按照static块的顺序来执行每个static块，并且只会执行一次。

### 能通过this访问静态成员变量吗？

```java
public class Main {　　
    static int value = 33;
 
    public static void main(String[] args) throws Exception{
        new Main().printValue();
    }
 
    private void printValue(){
        int value = 3;
        System.out.println(this.value);
    }
}
```

这里面主要考察队this和static的理解。this代表什么？this代表当前对象，那么通过new Main()来调用printValue的话，当前对象就是通过new Main()生成的对象。而static变量是被对象所享有的，因此在printValue中的this.value的值毫无疑问是33。在printValue方法内部的value是局部变量，根本不可能与this关联，所以输出结果是33。在这里永远要记住一点：静态成员变量虽然独立于对象，但是不代表不可以通过对象去访问，**所有的静态方法和静态变量都可以通过对象访问（只要访问权限足够）。**

## String的hashCode计算方式

计算公式为：
```java
s[0] * 31^(n-1) + s[1] * 31^(n-2) + s[n-1] * 31^0;
```

**为什么是31呢？**
因为hashcode是为了更好地区分对象，所以自然是分布越均匀越好。为了保证均匀分布，一般是采用选择一些比较大的素数（质数）。但是为什么不选33、37呢，这是因为`31 * i = (i << 5)- i`

这从底层转化为位运算，效率更好，所以31符合素数要求，同时也符合效率更快。



## Java异常

### throw和throws的区别

throw指的是这明确这个地方要抛出异常,需要具体的实现。而throws指的是在方法声明的时候，这个方法可能会抛出的异常。

```java
void doA(int a) throws Exception1,Exception3{
           try{
                 ......

           }catch(Exception1 e){
              throw e;
           }catch(Exception2 e){
              System.out.println("出错了！");
           }
           if(a!=b)
              throw new  Exception3("自定义异常");
}
```

- 代码块中可能会产生3个异常，(Exception1,Exception2,Exception3)。
- 如果产生Exception1异常，则捕获之后再抛出，由该方法的调用者去处理。
- 如果产生Exception2异常，则该方法自己处理了（即System.out.println("出错了！");）。所以该方法就不会再向外抛出Exception2异常了，void doA() throws Exception1,Exception3 里面的Exception2也就不用写了。
- 而Exception3异常是该方法的某段逻辑出错，程序员自己做了处理，在该段逻辑错误的情况下抛出异常Exception3，则该方法的调用者也要处理此异常。

### Java异常体系

![img](https://pic1.zhimg.com/80/v2-8aea704902cda3866941271653574894_720w.jpg)

Throwable 可以用来表示任何可以作为异常抛出的类，分为两种： **Error** 和 **Exception**。其中 Error 用来表示 JVM 无法处理的错误，Exception 又分为两种：

**（1）IOException受检异常** ：需要用 try…catch… 语句捕获并进行处理，并且可以从异常中恢复；

**（2）RuntimeException非受检异常** ：是程序运行时错误，例如空指针异常。

#### 异常处理

对于不同的异常，java采用不同的异常处理方式：

（1）Error（错误）：一般表示代码运行时JVM出现问题。比如NoClassDefFoundError等。比如说当jvm耗完可用内存时，将出现OutOfMemoryError。此类错误发生时，JVM将终止线程。

（2）运行异常将由系统自动抛出，应用本身可以选择处理或者忽略该异常。

（3）可查异常必须进行捕获或者抛出该方法之外交给上层处理。要么使用try-catch捕获，要么throws该异常。

## Object类有哪些公用方法

1. clone()
2. getClass()。获取运行时类型。
3. toString()
4. equals()
5. hashCode()
6. finalize()。释放资源，很少用到。
7. wait()方法。使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait方法一致在等待，直到获得锁或者被中断。调用该方法后当前线程进入睡眠状态，直到以下事件发生：1. 其他线程调用该对象的notify方法。2. 其他线程调用了该对象的notifyAll方法 3. 其他线程调用了interrupt中断该线程。4. 事件间隔到了。
8. notify方法。该方法唤醒在该对象上等待的某个线程。
9. notifyAll方法。该方法唤醒在该对象上等待的所有线程。

## Java并发

### 互斥锁、自旋锁、读写锁

1. 自旋锁。自旋锁指的是多个线程竞争同一个资源，同一时刻只能有一个线程在访问。采用自旋锁时，当加锁失败时，会用死循环一直尝试加锁，此时线程不会休眠，而是忙等待，无限尝试。

```cpp
while (抢锁(lock) == 没抢到) {
}
```

2. 互斥锁。互斥锁指的是多个线程竞争同一个资源，同一时刻只能有一个线程在访问。采用互斥锁，当加锁失败时，该线程会进入休眠状态，等待资源发生变化时，由操作系统负责通知和唤醒该线程。由于需要操作系统来负责调度，所以会涉及到上下文切换

```cpp
while (抢锁(lock) == 没抢到) {
}
```

3. 读写锁。允许读读，禁止读写，写读，写写。

```cpp
void 以读者身份加锁(rwlock) {
    加锁(rwlock.保护当前读者数量的锁);
    rwlock.当前读者数量 += 1;
    if (rwlock.当前读者数量 == 1) {
        加锁(rwlock.保护写操作的锁);
    }
    解锁(rwlock.保护当前读者数量的锁);
}

void 以读者身份解锁(rwlock) {
    加锁(rwlock.保护当前读者数量的锁);
    rwlock.当前读者数量 -= 1;
    if (rwlock.当前读者数量 == 0) {
        解锁(rwlock.保护写操作的锁);
    }
    解锁(rwlock.保护当前读者数量的锁);
}

void 以写者身份加锁(rwlock) {
    加锁(rwlock.保护写操作的锁);
}

void 以写者身份解锁(rwlock) {
    解锁(rwlock.保护写操作的锁);
}
```


### 用两个int值实现读写锁？

具体可以看这里https://www.cnblogs.com/DarrenChan/p/8619476.html

用代码实现了，写的不错。




## JVM

### 如何尽可能少的出现full gc

1. 避免创建大对象
2. 增大老年代空间
3. 尽可能使用标记-整理算法，使得内存空间变得更连续

## 创建线程的三种方法

### 继承Threads

### 实现Runnable接口

### 实现Callable接口



## IO事件

### select, poll, epoll是什么，有什么区别？

#### select

#### poll

#### epoll

##### int epoll_create(int size);

创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大。



##### int epoll_ctl(int epfd, int op, int fd, struct epoll_event \*event);

epoll的事件注册函数，它不同与select()是在监听事件时告诉内核要监听什么类型的事件，而是在这里先注册要监听的事件类型。

第一个参数是epoll_create()的返回值，第二个参数表示动作，用三个宏来表示：
EPOLL_CTL_ADD：注册新的fd到epfd中；
EPOLL_CTL_MOD：修改已经注册的fd的监听事件；
EPOLL_CTL_DEL：从epfd中删除一个fd；
第三个参数是需要监听的fd，第四个参数是告诉内核需要监听什么事，struct epoll_event结构如下：

```c
struct epoll_event {
  __uint32_t events;  /* Epoll events */
  epoll_data_t data;  /* User data variable */
};
```

events可以是以下几个宏的集合：
EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT：表示对应的文件描述符可以写；
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR：表示对应的文件描述符发生错误；
EPOLLHUP：表示对应的文件描述符被挂断；
EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里



##### int epoll_wait(int epfd, struct epoll_event \* events, int maxevents, int timeout);

等待事件的产生，类似于select()调用。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。



#### 工作模式

epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：

　　LT模式：**当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。**

　　ET模式：**当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。**

ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。

**epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。**




#### 三者区别

1. **支持一个进程所能打开的最大连接数**

select在32位机支持连接的个数为1024个，在64位机支持连接的个数为2048个。poll没有连接个数的限制，因为它是基于链表的。epoll虽然有限制，但是可以连接的数量非常大，1G内存的机器可以打开10W个连接。

2. **FD剧增后带来的IO效率问题**

select和poll由于是无差别轮训，对FD进行线性扫描，所以FD数量越大，效率越低。epoll会把哪个流发生什么样的I/O事件通知我们，而且只管活跃的连接，而并不管总连接有多大。epoll是通过每个fd上的callback实现的。

3. **消息传递方式**

select需要将用户空间的数据传递到内核空间。而poll,epoll则是通过用户空间和内核空间共享一块内存来实现的。

https://zhuanlan.zhihu.com/p/63179839

https://zhuanlan.zhihu.com/p/64138532

https://zhuanlan.zhihu.com/p/64746509



### 零拷贝

零拷贝主要有三种实现方式：

#### 用户态直接I/O。

这种方式使得用户进程直接在用户态访问外部设备，数据跨内核传输，提高了性能。但是这种方法只适合不需要内核缓冲区的程序，比如数据库管理系统，它在进程地址空间有自己的数据缓存机制。

### 减少拷贝次数

#### mmap+write

使用 mmap + write 代替原来的 read + write 方式，减少一次cpu拷贝。

整个拷贝过程会发生 4 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝。

![8](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggj9hkdcw0j30i50bv405.jpg)

缺点：mmap 隐藏着一个陷阱，当使用 mmap 映射一个文件时，如果这个文件被另一个进程所截获，那么 write 系统调用会因为访问非法地址被 SIGBUS 信号终止

#### sendfile

通过 sendfile 系统调用，数据可以直接在内核空间内部进行 I/O 传输，从而省去了数据在用户空间和内核空间之间的来回拷贝。

![9](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggj9hpo5q8j30il0bc3zy.jpg)

整个拷贝过程会发生 2 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝。

#### sendfile + DMA gather copy

Linux 2.4 版本的内核对 sendfile 系统调用进行修改，为 DMA 拷贝引入了 gather 操作。它将内核空间 (kernel space) 的读缓冲区 (read buffer) 中对应的数据描述信息 (内存地址、地址偏移量) 记录到相应的网络缓冲区( (socket buffer) 中，由 DMA 根据内存地址、地址偏移量将数据批量地从读缓冲区 (read buffer) 拷贝到网卡设备中，这样就省去了内核空间中仅剩的 1 次 CPU 拷贝操作。

![10](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggj9hotf1zj30hy0bq0u8.jpg)

基于 sendfile + DMA gather copy 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换、0 次 CPU 拷贝以及 2 次 DMA 拷贝。



### Java NIO Buffer、Channel、Selector

### BIO和NIO的区别

1. BIO以流的方式处理数据，而NIO以块的方式处理数据，块I/O的效率比流I/O高很多；

2. BIO是阻塞的，NIO是非阻塞的；

3. BIO基于字节流和字符流进行操作，而NIO基于Channel（通道）和Buffer（缓冲区）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector（选择器）用于监听多个通道的时间（比如：连接请求，数据到达等），因此使用单个线程就可以监听多个客户端通道；

4. BIO是单向的，如：InputStream, OutputStream；而NIO是双向的，既可以用来进行读操作，又可以用来进行写操作。



#### Buffer

一个 Buffer 本质上是内存中的一块，我们可以将数据写入这块内存，之后从这块内存获取数据。

java.nio 定义了以下几个 Buffer 的实现，这个图读者应该也在不少地方见过了吧。

![img](https://pic1.zhimg.com/80/v2-59754ab9d9c1df26f583cf7fcd5d5e04_720w.jpg)

- capacity。buffer最大容量。
- position的初始值是 0，每往 Buffer 中写入一个值，position 就自动加 1，代表下一次的写入位置。读操作的时候也是类似的，每读一个值，position 就自动加 1。

- limit。读的时候代表所能实际读取的大小。写的时候代表capacity大小。

### Channel

channel的三大特性：

1. 一个通道既可以读数据也可以写数据，但是流是单向的通道（只能读或写）
2. 通道能够异步的进行读写数据
3. 从缓冲区读写数据总是通过通道进行



所有的 NIO 操作始于通道，通道是数据来源或数据写入的目的地，主要地，我们将关心 java.nio 包中实现的以下几个 Channel：

![img](https://pic1.zhimg.com/80/v2-1ba83e351df6da107860551eca3ee7c0_720w.jpg)

- FileChannel：文件通道，用于文件的读和写
- DatagramChannel：用于 UDP 连接的接收和发送
- SocketChannel：把它理解为 TCP 连接通道，简单理解就是 TCP 客户端
- ServerSocketChannel：TCP 对应的服务端，用于监听某个端口进来的请求

这里不是很理解这些也没关系，后面介绍了代码之后就清晰了。还有，我们最应该关注，也是后面将会重点介绍的是 SocketChannel 和 ServerSocketChannel。

channel详情：https://segmentfault.com/a/1190000006824107



### Selector

Selector 建立在非阻塞的基础之上，大家经常听到的 多路复用 在 Java 世界中指的就是它，用于实现一个线程管理多个 Channel。

步骤如下：

1. 首先，我们开启一个 Selector。你们爱翻译成选择器也好，多路复用器也好。
Selector selector = Selector.open();
2. 将 Channel 注册到 Selector 上。前面我们说了，Selector 建立在非阻塞模式之上，所以注册到 Selector 的 Channel 必须要支持非阻塞模式，FileChannel 不支持非阻塞，我们这里讨论最常见的 SocketChannel 和 ServerSocketChannel。
// 将通道设置为非阻塞模式，因为默认都是阻塞模式的 channel.configureBlocking(false); // 注册 SelectionKey key = channel.register(selector, SelectionKey.OP_READ);
register 方法的第二个 int 型参数（使用二进制的标记位）用于表明需要监听哪些感兴趣的事件，共以下四种事件：
SelectionKey.OP_READ
对应 00000001，通道中有数据可以进行读取
SelectionKey.OP_WRITE
对应 00000100，可以往通道中写入数据
SelectionKey.OP_CONNECT
对应 00001000，成功建立 TCP 连接
SelectionKey.OP_ACCEPT
对应 00010000，接受 TCP 连接






# MySQL

## mysql为什么推荐自增主键？

因为自增主键可以使插入的数据在物理上是连续的，性能更好，主要是防止页分裂。

**页分裂**

mysql （注意本文讲的 mysql 默认为InnoDB 引擎）底层数据结构是 B+ 树，**所谓的索引其实就是一颗 B+ 树，一个表有多少个索引就会有多少颗 B+ 树，mysql 中的数据都是按顺序保存在 B+ 树上的**（所以说索引本身是有序的）。

然后 mysql 在底层又是以数据页为单位来存储数据的，一个数据页大小默认为 16k，当然你也可以自定义大小，也就是说如果一个数据页存满了，mysql 就会去申请一个新的数据页来存储数据。

如果主键为自增 id 的话，mysql 在写满一个数据页的时候，直接申请另一个新数据页接着写就可以了。

如果主键是非自增 id，为了确保索引有序，mysql 就需要将每次插入的数据都放到合适的位置上。

当往一个快满或已满的数据页中插入数据时，新插入的数据会将数据页写满，mysql 就需要申请新的数据页，并且把上个数据页中的部分数据挪到新的数据页上。

这就造成了页分裂，这个大量移动数据的过程是会严重影响插入效率的。


## 自增主键在删除数据后的变化？

### 未重启数据库的情况

未重启数据库的情况下，其innodb内部计数器继续工作，并通过binglog持久化。也就是删除数据后，再新增数据，那么此时新增的主键id值为内部计数器的值，不会受到删除数据的影响。

```bash
1,3,5,7,9
delete 7，9，此时变成1，3，5
未重启add一条数据后，变成1，3，5，11
```

### 重启数据库的情况

关闭数据库后重启数据库后，数据库重新初始化，通过已有的数据最大键值为基数。
```bash
1,3,5,7,9
delete 7，9，此时编程1，3，5
重启add一条数据后，变成1，3，5，7
```

## MySQL为什么使用B+树做索引

- 在B+树的基础上每个节点存储的关键字数更多，树的层级更少所以查询数据更快

- 所有关键字数据都存在叶子节点，所以每次查找的次数都相同，查询速度比B树更稳定。

- 除此之外，B+树的叶子节点是跟后序节点相连接的，这对范围查找是非常有用的。
- 
- 因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出）
- 指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低；




## MySQL锁的类型：

### 行级锁：

- 共享锁(S锁)，允许事务读取该行。
- 独占锁(X锁)，允许事务对行进行更新或删除。

S 锁和 S 锁是 兼容 的，X 锁和其它锁都 不兼容。

### 表级锁

- 意向共享锁(IS)，事务即将给表中的各个行设置共享锁，事务给数据行加 S 锁前必须获得该表的 IS 锁。
- 意向独占锁(IX)，事务即将给表中的各个行设置排他锁，事务给数据行加 X 锁前必须获得该表 IX 锁。

意向锁的主要目的是为了使得 行锁 和 表锁 共存。

## MySQL死锁怎么办？

innodb通过wait-for-graph等待图的方式，来检测死锁。当检测到死锁发生时，会自动回滚一个事务。

## MySQL锁的优化建议

- 在业务环境允许的情况下，尽量使用较低级别的事务隔离，以减少 MySQL 因为实现事务隔离级别所带来的附加成本。
- 合理设计索引，让 InnoDB 在索引键上面加锁的时候尽可能准确，尽可能的缩小锁定范围，避免造成不必要的锁定而影响其他 Query 的执行。

## MySQL主从同步？

 从数据库(Slave)是主数据库的备份，当主数据库(Master)变化时从数据库要更新，这些数据库软件可以设计更新周期。这是提高信息安全的手段。主从数据库服务器不在一个地理位置上，当发生意外时数据库可以保存。

### 主从分工

其中Master负责写操作的负载，也就是说一切写的操作都在Master上进行，而读的操作则分摊到Slave上进行。这样一来的可以大大提高读取的效率。在一般的互联网应用中，经过一些数据调查得出结论，读/写的比例大概在 10：1左右 ，也就是说大量的数据操作是集中在读的操作，这也就是为什么我们会有多个Slave的原因。但是为什么要分离读和写呢？熟悉DB的研发人员都知道，写操作涉及到锁的问题，不管是行锁还是表锁还是块锁，都是比较降低系统执行效率的事情。我们这样的分离是把写操作集中在一个节点上，而读操作其其他的N个节点上进行，从另一个方面有效的提高了读的效率，保证了系统的高可用性。

### 用途

- 读写分离，提供查询服务
- 备份，避免影响业务

### 条件

- 主库开启binlog日志（设置log-bin参数）
- 主从server-id不同
- 从库服务器能连通主库

### 主从复制主流架构

- 一主一从，一主多从。一主一从和一主多从是最常见的主从架构方式，一般实现主从配置或者读写分离都可以采用这种架构。如果是一主多从的模式，当 Slave 增加到一定数量时，Slave 对 Master 的负载以及网络带宽都会成为一个严重的问题。

- 多主一从。MySQL 5.7 开始支持多主一从的模式，将多个库的数据备份到一个库中存储。

- 主主复制。理论上跟主从一样，但是两个MySQL服务器互做对方的从，任何一方有变更，都会复制对方的数据到自己的数据库。双主适用于写压力比较大的业务场景，或者 DBA 做维护需要主从切换的场景，通过双主架构避免了重复搭建从库的麻烦。（主从相互授权连接，读取对方binlog日志并更新到本地数据库的过程；只要对方数据改变，自己就跟着改变）

- 级联复制。级联模式下因为涉及到的 slave 节点很多，所以如果都连在 master 上对主服务器的压力肯定是不小的。所以部分 slave 节点连接到它上一级的从节点上。这样就缓解了主服务器的压力。

级联复制解决了一主多从场景下多个从库复制对主库的压力，带来的弊端就是数据同步延迟比较大。


### 主从复制原理

主库：binlong dump 线程，当数据发生变化时，会写入到按序写到Binlog，然后通知从库。
从库：1. 从库的I/O线程会请求主库的binlog，然后写入到relay log文件中。2. 然后SQL线程通过读取relay log，依次解析SQL语句。

![4](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjx1ms5ezhj312s0imtb5.jpg)





### MySQL 基于 Binlog 主从复制的模式介绍

MySQL 主从复制默认是 **异步的模式**。MySQL增删改操作会全部记录在 Binlog 中，当 slave 节点连接 master 时，会主动从 master 处获取最新的 Binlog 文件。并把 Binlog 存储到本地的 relay log 中，然后去执行 relay log 的更新内容。

##### 异步模式 (async-mode)

异步模式如下图所示：

![6](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjx1mu02wbj31160kk0vj.jpg)

这种模式下，主节点不会主动推送数据到从节点，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主节点如果崩溃掉了，此时主节点上已经提交的事务可能并没有传到从节点上，如果此时，强行将从提升为主，可能导致新主节点上的数据不完整。

##### 半同步模式(semi-sync)

介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到 relay log 中才返回成功信息给客户端（只能保证主库的 Binlog 至少传输到了一个从节点上），否则需要等待直到超时时间然后切换成异步模式再提交。

![7](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjx1muypwdj31420jg41q.jpg)

相对于异步复制，半同步复制提高了数据的安全性，一定程度的保证了数据能成功备份到从库，同时它也造成了一定程度的延迟，但是比全同步模式延迟要低，这个延迟最少是一个 TCP/IP 往返的时间。所以，半同步复制最好在低延时的网络中使用。

半同步模式不是 MySQL 内置的，从 MySQL 5.5 开始集成，需要 master 和 slave 安装插件开启半同步模式。

##### 全同步模式

指当主库执行完一个事务，然后所有的从库都复制了该事务并成功执行完才返回成功信息给客户端。因为需要等待所有从库执行完该事务才能返回成功信息，所以全同步复制的性能必然会收到严重的影响。


### 主从复制可能会出现的主从同步延迟问题？

从库的I/O线程是单线程的解析，当主库写入速度很快的时候，从库可能会更不上。


## MySQL MVCC理解？

MVCC是一种多版本并发控制机制。

### MVCC是为了解决什么问题?

MVCC是在并发访问数据库时，通过对数据进行多版本控制，避免因写锁而导致读操作的堵塞，从而很好的优化并发堵塞问题。解决并发问题的通用方案有：

1. 对并发访问的数据添加一把排它锁，添加锁之后，其他的读和写操作都需等待锁释放后才能访问。
2. 添加一把共享锁，读读操作不需要等待锁的释放，读写和写写操作需要等待锁的释放。
3. 通过对并发数据进行快照备份，从而达到无锁数据的并发访问。

通俗的讲就是MVCC通过对数据进行多版本保存，根据比较版本号来控制数据是否展示，从而达到读取数据时无需加锁就可以实现事务的隔离性。



### MVCC实现

InnoDB的MVCC,是通过在每行**记录后面保存两个隐藏的列来实现的**。这两个列，分别保存了这个行的创建时间，一个保存的是行的删除时间。这里存储的并不是实际的时间值,而是系统版本号(可以理解为事务的ID)，每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID.下面看一下在REPEATABLE READ隔离级别下,MVCC具体是如何操作的.

#### Select

- InnoDB只会查找版本早于当前事务版本的数据行(也就是,行的系统版本号小于或等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的.
- 行的删除版本要么未定义,要么大于当前事务版本号,这可以确保事务读取到的行，在事务开始之前未被删除.
  只有a,b同时满足的记录，才能返回作为查询结果.

#### Delete

InnoDB会为删除的每一行保存当前系统的版本号(事务的ID)作为删除标识.

#### Update

InnoDB执行UPDATE，实际上是新插入了一行记录，并保存其创建时间为当前事务的ID，同时保存当前事务ID到要UPDATE的行的删除时间.

### MVCC实现原理

MVCC的两个实现核心是undo log和一致性视图，通过undo log来保存多版本的数据，通过一致性视图来保存当前活跃的事务列表，将两者结合和制定一定的规则来判断当前可读数据。

#### undo log
innodb在修改数据库数据记录之前会先在undo log中记录回滚日志，日志的内容为：执行insert时会对应在undo log中记录一条delete语句，并且会记录这个版本的事务id(txid)，执行update语句会有一条update语句来使之数据恢复到上个版本。

undo log主要用于事务回滚和mvcc获取不同事务id对应的数据来实现事务隔离。

#### 一致性视图

InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。简而言之一致性视图是个数组，记录了当前活跃的事务ID，通过这个数据我们可以判断出来事务执行的先后顺序，事务所能读取的数据版本。

# 计算机网络

## 什么SYN泛洪攻击？怎么解决

![img](https://oscimg.oschina.net/oscnet/ddfa286fa10740fea0370d0496d8e759247.png)

在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。

SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击。



检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行。

```bash
netstat -nap | grep SYN_RECV
```



**解决方案：**

当服务器接受到 SYN 报文段时，不直接为该 TCP 分配资源，而只是打开一个半开的套接字。接着会使用 SYN 报文段的源 Id，目的 Id，端口号以及只有服务器自己知道的一个秘密函数生成一个 cookie，并把 cookie 作为序列号响应给客户端。

如果客户端是正常建立连接，将会返回一个确认字段为 cookie + 1 的报文段。接下来服务器会根据确认报文的源 Id，目的 Id，端口号以及秘密函数计算出一个结果，如果结果的值 + 1 等于确认字段的值，则证明是刚刚请求连接的客户端，这时候才为该 TCP 分配资源。

这样一来就不会为恶意攻击的 SYN 报文段分配资源空间，避免了攻击。


## 详细介绍一下 TCP 的四次挥手机制，为什么要有 TIME_WAIT 状态，为什么需要四次挥手？服务器出现了大量 CLOSE_WAIT 状态如何解决

当客户端要服务器断开连接时，客户端 TCP 会向服务器发送一个特殊的报文段，该报文段的 FIN 标志位会被置 1，接着服务器会向客户端发送一个确认报文段。然后服务器也会客户端发送一个 FIN 标志位为 1 的终止报文段，随后客户端回送一个确认报文段，服务器立即断开连接。客户端等待一段时间后也断开连接。

其实四次挥手的过程是很容易理解的，由于 TCP 协议是全双工的，也就是说客户端和服务端都可以发起断开连接。两边各发起一次断开连接的申请，加上各自的两次确认，看起来就像执行了四次挥手。

为什么要有 TIME_WAIT 状态？因为客户端最后向服务器发送的确认 ACK 是有可能丢失的，当出现超时，服务端会再次发送 FIN 报文段，如果客户端已经关闭了就收不到了。还有一点是避免新旧连接混杂。

大量 CLOSE_WAIT 表示程序出现了问题，对方的 socket 已经关闭连接，而我方忙于读或写没有及时关闭连接，需要检查代码，特别是释放资源的代码，或者是处理请求的线程配置。

## 详细讲一下TCP的滑动窗口

![image-20210310141114449](/Users/bird/Downloads/面试相关/面试经验/image-20210310141114449.png)

从上面的图可以看到滑动窗口左边的是已发送并且被确认的分组，滑动窗口右边是还没有轮到的分组。滑动窗口里面也分为两块，一块是已经发送但是未被确认的分组，另一块是窗口内等待发送的分组。随着已发送的分组不断被确认，窗口内等待发送的分组也会不断被发送。整个窗口就会往右移动，让还没轮到的分组进入窗口内。

可以看到滑动窗口起到了一个限流的作用，也就是说当前滑动窗口的大小决定了当前 TCP 发送包的速率，而滑动窗口的大小取决于拥塞控制窗口和流量控制窗口的两者间的最小值。



**流量控制:**

TCP 是全双工的，客户端和服务器均可作为发送方或接收方，我们现在假设一个发送方向接收方发送数据的场景来讲解流量控制。首先我们的接收方有一块接收缓存，当数据来到时会先把数据放到缓存中，上层应用等缓存中有数据时就会到缓存中取数据。假如发送方没有限制地不断地向接收方发送数据，接收方的应用程序又没有及时把接收缓存中的数据读走，就会出现缓存溢出，数据丢失的现象，为了解决这个问题，我们引入流量控制窗口。

假设应用程序最后读走的数据序号是 lastByteRead，接收缓存中接收到的最后一个数据序号是 lastByteRcv，接收缓存的大小为 RcvSize，那么必须要满足 lastByteRcv - lastByteRead <= RcvSize 才能保证接收缓存不会溢出，所以我们定义流量窗口为接收缓存剩余的空间，也就是 Rcv = RcvSize - (lastByteRcv - lastByteRead)。只要接收方在响应 ACK 的时候把这个窗口的值带给发送方，发送方就能知道接收方的接收缓存还有多大的空间，进而设置滑动窗口的大小。



**拥塞控制:**

拥塞控制是指发送方先设置一个小的窗口值作为发送速率，当成功发包并接收到 ACK 时，便以指数速率增大发送窗口的大小，直到遇到丢包（超时/三个冗余 ACK ），才停止并调整窗口的大小。这么做能最大限度地利用带宽，又不至于让网络环境变得太过拥挤。

最终滑动窗口的值将设置为流量控制窗口和拥塞控制窗口中的较小值。



## 讲一下 HTTP 与 HTTPS 的区别?

**具体可以看看这个链接，讲得很清晰https://zhuanlan.zhihu.com/p/25976060**

HTTP 和 HTTPS 的主要区别在于 HTTP 协议传递的是明文数据，而 HTTPS 传递的是加密过的数据，也就是说 HTTPS 更具有安全性。也正由 HTTPS 需要保证安全性，所以它的性能要比 HTTP 差一点。

单说安全性肯定是不够的，我打算扩展讲一下 HTTPS 是怎么解决安全性问题的，通过这些 HTTP 没有机制，反映出 HTTPS 与 HTTP 的区别。下面尝试把 HTTPS 加密的过程推导出来。推导过程不涉及复杂的实现细节：

### 如何安全地进行数据传输？

假设现在 A 和 B 要进行安全的通信，那么究竟怎样才算是安全的通信？很自然地会想到：A 和 B 之间传递数据，这些数据只有 A 和 B 才看得懂，中间人就算截取了信息但也看不懂，这才算得上安全。

### 安全通信的处理手段：

为了能让 A 和 B 才能看懂，就必须要对数据进行加密，而且首先想到的就是对称加密。对称加密的意思是 A 和 B 各持有一个相同的密钥，它们传递信息时会用密钥给信息加密，在消息到达端给消息解密，完成安全通信。

在对称加密中又会涉及到加密算法的选择问题。现实世界中，通常是多个客户端面向一个服务器的情况，不可能让每个客户端和服务器之间都采用相同的加密算法，如果是这样那和没加密差不多。所以注定每个客户端和服务器之间都会采用不同的加密方式。

### 如何让每个客户端与服务器之间都采用不同的加密方式？

要想对不同的机器使用不同的加密方式，最直接想到的就是使用随机数。也就说客户端和服务器之间每次都基于一个随机数产生加密算法。（具体实现时为了保证随机，用到还不止一个随机数）

这个产生加密算法的过程称之为协商，现在问题是协商的过程是透明的，也就是说中间人可以截获协商的过程，从而知道我们的加密方式。为了解决这个问题，我们需要对协商的过程进行加密。

### 如何对协商的过程进行加密？

之所以能来到这一步，是因为我们一开始就选择使用了对称加密，也就说一开始的对称加密导致了现在的问题，所以这时我们不能再使用对称加密了，否则会陷入死循环。

在密码学领域，还有一种加密过程叫非对称加密，它的逻辑是这样的：通信双方一方持有私钥，一方持有公钥，经过私钥加密的信息，都能通过公钥进行解密。但是经过公钥加密的数据，只有私钥可以解密。

按照非对称加密的规则，我们让服务器持有私钥，让客户端持有公钥。这样就能保证客户端给服务器发送消息的时候是安全的（相反，服务器给客户端发送消息就是不安全的），我们可以把协商时重要的逻辑安排在客户端给服务器发送信息的过程中，从而保证了协商过程的安全性。

### 客户端如何获得公钥？

现在用非对称加密算法解决了协商的安全问题，但是非对称加密的前提是客户端需要获得公钥，这又是一个问题了，客户端与服务器打交道之前是互不知道双方身份的，怎么才能让客户端获得公钥呢？

也就只有两种办法：

1. 客户端向服务器要公钥
2. 客户端向一个远程的公共服务器获取公钥

方法2显然是不行的，尚且不说多了一个访问节点，如何找到公共服务器的地址也是一个待解决的问题，所以还是使用方法 1。

但是方法 1 存在一个问题：如果中间人把服务器发送给客户端的公钥调包了怎么办？也就是说客户端无法知道发送公钥的是否是正真的服务器。

### 引入第三方机构解决问题

客户端无法辨识服务端和中间人的问题称为“身份验证”问题，也就是说我们需要为服务器向客户端发送公钥的过程进行加密。

这下完了，之前我们因遇到对称加密的瓶颈选择了非对称加密，现在使用非对称加密也遇到了瓶颈。显然这两种加密方式都是不可用的了，否则会再次陷入死循环。

接下来我们只好通过第三方机构的介入，解决这个问题。首先我们自己保存有第三方权威机构的公钥，然后第三方机构使用私钥对服务器将要发送给客户端的公钥进行加密，客户端接收到这个经加密的公钥后（数字证书），就能通过自己保存的第三方机构公钥进行解密。

> “到这里为止，我们解释了 HTTPS 中使用到的对称加密，非对称加密，CA，数字证书的概念，但是还差一个叫数字签名的概念没有解释。

在现实生活中，CA 不单止会给我们正常公司发放证书，还会给中间人的坏公司发放证书，如果中间人把发放的证书调包了怎么办？这时我们仍能用 CA 的私钥进行解密，但是证书已经被调包了。

那么客户端怎样验证证书的真伪呢？答案是证书本身会告诉客户端如何辨认真伪。比方说证书上面有一个证书编号，还有一个如何计算证书编号的方法，客户端可以根据计算证书编号的方法计算出自己要获得的证书的编号，然后把这个编号和证书上的编号进行比对，如果一样证明没有被调包。

这里的证书编号指的就是数字签名，证书指的就是数字证书。

总结一下 HTTPS ：HTTPS 想要保证客户端与服务器之间的通信安全，就得使用对称加密算法进行加密。协商对称加密算法的过程通过非对称加密算法来保证。在非对称加密算法中，客户端获得公钥的过程需要第三方机构（CA）通过颁发数字证书保证安全性。

总得来说通过这一系列机制协商出了一个对称加密算法后，客户端与服务器之间就能通过该算法进行安全的通信了。

## nginx负载均衡的算法怎么实现的？

1. 轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
2. weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
3. ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
4. fair（第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 


# 网络编程

## socket

 应用层的各种网络应用程序基本上都是通过 Linux Socket 编程接口来和内核空间的网络协议栈通信的。

从层次上来说，它位于应用层，是操作系统为应用程序员提供的 API，通过它，应用程序可以访问传输层协议。

- socket 位于传输层协议之上，屏蔽了不同网络协议之间的差异
- socket 是网络编程的入口，它提供了大量的系统调用，构成了网络程序的主体
- 在Linux系统中，socket 属于文件系统的一部分，网络通信可以被看作是对文件的读取，使得我们对网络的控制和对文件的控制一样方便。



![bbfc5256bf5c1cf061f4a641ace6eaacad3.jpg](https://oscimg.oschina.net/oscnet/bbfc5256bf5c1cf061f4a641ace6eaacad3.jpg)

![0f11da90ca60acfe30c323dd68b3264449d.jpg](https://oscimg.oschina.net/oscnet/0f11da90ca60acfe30c323dd68b3264449d.jpg)





**一、服务器**

1、建立连接阶段

调用socket()，分配文件描述符，即监听套接字

调用bind()，将套接字与本地IP地址和端口绑定

调用listen()，监听特定端口，socket()创建的套接字是主动的，调用listen使得该文件描述符为监听套接字，变主动为被动

调用accept()，阻塞等待客户端连接

2、数据交互阶段

调用read()，阻塞等待客户端发送的请求，收到请求后从read()返回，处理客户端请求

调用write()，将处理结果发送给客户端，然后继续调用read()等待客户端请求

3、关闭连接

当read()返回0的时候，说明客户端发来了FIN数据包，即关闭连接，也会调用close()关闭连接套接字和监听套接字

**二、客户端**

1、建立连接阶段

调用socket()，分配文件描述符

调用connect()，向服务器发送建立连接请求

2、数据交互阶段

调用write()，将请求发送给服务器

调用read()，阻塞等待服务器应答

3、关闭连接

当没有数据发送的时候，调用close()关闭连接套接字，即关闭连接，向服务器发送FIN数据报

**三、TCP通信过程**



![img](https://pic3.zhimg.com/80/v2-bceaf0520685ae3c210b31ff807b97a6_720w.jpg)
